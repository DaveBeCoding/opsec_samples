### Overview 

|               | Precision | Recall | F1-Score | Support |
|---------------|-----------|--------|----------|---------|
| 0             | 1.00      | 1.00   | 1.00     | 194689  |
| 1             | 1.00      | 1.00   | 1.00     | 784998  |
|               |           |        |          |         |
| Accuracy      |           |        | 1.00     | 979687  |
| Macro Avg     | 1.00      | 1.00   | 1.00     | 979687  |
| Weighted Avg  | 1.00      | 1.00   | 1.00     | 979687  |

### Further Detailed Report

| Metric | Description | Class 0 Value | Class 1 Value |
|---|---|---|---|
| Precision | Ratio of correctly predicted positive observations to the total predicted positives | 1.00 | 1.00 |
| Recall (Sensitivity) | Ratio of correctly predicted positive observations to all observations in actual class | 1.00 | 1.00 |
| F1-Score | Weighted average of Precision and Recall | 1.00 | 1.00 |
| Support | Number of occurrences of each class in the true response variable | 194,689 | 784,998 |
| Accuracy | Ratio of correctly predicted observations to the total observations | 1.00 | 1.00 |
| Macro Avg | Average of the metrics for each class, without considering the proportion of each class in the data | 1.00 | 1.00 |
| Weighted Avg | Average of the metrics for each class, considering the proportion of each class in the data | 1.00 | 1.00 |

### Context of returned values

- The classifier is performing perfectly, classifying every instance correctly.
- This is quite rare in real-world scenarios, This is a simple example:
  - In real world settings check/ensure the model isn't overfitting the data.
- Perfect scores are quite rare.


### Data

| Source |
| ------ |
| [UCI KDD Cup 99 Data](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html) |

